{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e7e26e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import warnings\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865cc52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'BENIGN': np.int64(0), 'Bot': np.int64(1), 'DDoS': np.int64(2), 'DoS Hulk': np.int64(3), 'DoS Slowhttptest': np.int64(4), 'DoS slowloris': np.int64(5), 'FTP-Patator': np.int64(6), 'Infiltration': np.int64(7), 'PortScan': np.int64(8), 'SSH-Patator': np.int64(9), 'Web Attack \\x96 Brute Force': np.int64(10), 'Web Attack \\x96 Sql Injection': np.int64(11), 'Web Attack \\x96 XSS': np.int64(12)}\n"
     ]
    }
   ],
   "source": [
    "# Step 1. Load Dataset\n",
    "df = pd.read_csv('CIC_IDS_2017_cleaned.csv')\n",
    "\n",
    "# Define identifiers\n",
    "identifiers = ['Flow ID', 'Source IP', 'Destination IP', 'Timestamp', 'Source Port', 'Destination Port', 'Protocol']\n",
    "label_col = 'Label'\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df[label_col] = label_encoder.fit_transform(df[label_col])\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Dataset Downsample\n",
    "X_full = df.drop(columns=[label_col])\n",
    "y_full = df[label_col]\n",
    "\n",
    "X_down, _, y_down, _ = train_test_split(\n",
    "    X_full, y_full,\n",
    "    train_size=0.05,  # 5% of original dataset\n",
    "    stratify=y_full,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Split Features, Metadata, Labels\n",
    "# Separate ML features and metadata\n",
    "X_down_features = X_down.drop(columns=identifiers)\n",
    "meta_down = X_down[identifiers]\n",
    "\n",
    "X_train, X_test, y_train, y_test, meta_train, meta_test = train_test_split(\n",
    "    X_down_features, y_down, meta_down,\n",
    "    test_size=0.05,  # small test set\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397ab587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest Evaluation ===\n",
      "Accuracy: 0.9980882864094542\n",
      "Confusion Matrix:\n",
      " [[4799    0    0    1    0    1    0    0    0    0]\n",
      " [   3    3    0    0    0    0    0    0    0    0]\n",
      " [   2    0  318    0    0    0    0    0    0    0]\n",
      " [   4    0    0  215    0    0    0    0    0    0]\n",
      " [   0    0    0    0   14    0    0    0    0    0]\n",
      " [   0    0    0    0    0   11    0    0    0    0]\n",
      " [   0    0    0    0    0    0   15    0    0    0]\n",
      " [   0    0    0    0    0    0    0  356    0    0]\n",
      " [   0    0    0    0    0    0    0    0   11    0]\n",
      " [   0    0    0    0    0    0    0    0    0    1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4801\n",
      "           1       1.00      0.50      0.67         6\n",
      "           2       1.00      0.99      1.00       320\n",
      "           3       1.00      0.98      0.99       219\n",
      "           4       1.00      1.00      1.00        14\n",
      "           5       0.92      1.00      0.96        11\n",
      "           6       1.00      1.00      1.00        15\n",
      "           8       1.00      1.00      1.00       356\n",
      "           9       1.00      1.00      1.00        11\n",
      "          10       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00      5754\n",
      "   macro avg       0.99      0.95      0.96      5754\n",
      "weighted avg       1.00      1.00      1.00      5754\n",
      "\n",
      "\n",
      "=== XGBoost Evaluation ===\n",
      "Accuracy: 0.9994786235662148\n",
      "Confusion Matrix:\n",
      " [[4801    0    0    0    0    0    0    0    0    0]\n",
      " [   1    5    0    0    0    0    0    0    0    0]\n",
      " [   1    0  319    0    0    0    0    0    0    0]\n",
      " [   1    0    0  218    0    0    0    0    0    0]\n",
      " [   0    0    0    0   14    0    0    0    0    0]\n",
      " [   0    0    0    0    0   11    0    0    0    0]\n",
      " [   0    0    0    0    0    0   15    0    0    0]\n",
      " [   0    0    0    0    0    0    0  356    0    0]\n",
      " [   0    0    0    0    0    0    0    0   11    0]\n",
      " [   0    0    0    0    0    0    0    0    0    1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4801\n",
      "           1       1.00      0.83      0.91         6\n",
      "           2       1.00      1.00      1.00       320\n",
      "           3       1.00      1.00      1.00       219\n",
      "           4       1.00      1.00      1.00        14\n",
      "           5       1.00      1.00      1.00        11\n",
      "           6       1.00      1.00      1.00        15\n",
      "           8       1.00      1.00      1.00       356\n",
      "           9       1.00      1.00      1.00        11\n",
      "          10       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00      5754\n",
      "   macro avg       1.00      0.98      0.99      5754\n",
      "weighted avg       1.00      1.00      1.00      5754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4. Train Models\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_preds = xgb.predict(X_test)\n",
    "\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    print(f\"\\n=== {name} Evaluation ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "\n",
    "evaluate_model(\"Random Forest\", y_test, rf_preds)\n",
    "evaluate_model(\"XGBoost\", y_test, xgb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42123256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5. Prepare Predictions with Metadata\n",
    "predicted_label_names = [label_encoder.inverse_transform([lbl])[0] for lbl in xgb_preds]\n",
    "\n",
    "predictions_df = pd.concat([\n",
    "    meta_test.reset_index(drop=True),\n",
    "    pd.DataFrame({\n",
    "        \"True_Label\": label_encoder.inverse_transform(y_test),\n",
    "        \"Predicted_Label\": predicted_label_names\n",
    "    })\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377922c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6. Gemini API Setup\n",
    "GEMINI_API_KEY = \"AIzaSyBNnV4Qix9NDA8UQpCov9SaurNWGy2dqzU\"\n",
    "GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=\" + GEMINI_API_KEY\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "def generate_playbook(incident_type, src_ip='Unknown', dst_ip='Unknown', protocol='Unknown'):\n",
    "    prompt = f\"\"\"\n",
    "A '{incident_type}' incident has been detected.\n",
    "Source IP: {src_ip}\n",
    "Destination IP: {dst_ip}\n",
    "Protocol: {protocol}\n",
    "\n",
    "Suggest a concise, practical response playbook in strictly less that 2500 characters, covering:\n",
    "- Identification\n",
    "- Containment\n",
    "- Eradication\n",
    "- Recovery\n",
    "\"\"\"\n",
    "    body = {\"contents\": [{\"parts\": [{\"text\": prompt.strip()}]}]}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(GEMINI_API_URL, headers=headers, json=body)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error from Gemini:\", e)\n",
    "        return \"Failed to generate response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb1d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… All predictions and playbooks saved in Playbooks.csv\n"
     ]
    }
   ],
   "source": [
    "#Step 7. Generate Playbooks for CSV output\n",
    "max_playbook_length = 2500  # approximate max characters per playbook\n",
    "incident_playbooks = {}\n",
    "\n",
    "unique_incidents = predictions_df[\"Predicted_Label\"].unique()\n",
    "\n",
    "for incident in unique_incidents:\n",
    "    if incident.lower() == \"benign\":\n",
    "        continue\n",
    "\n",
    "    # Take first occurrence for metadata\n",
    "    row = predictions_df[predictions_df[\"Predicted_Label\"] == incident].iloc[0]\n",
    "    playbook_text = generate_playbook(\n",
    "        incident,\n",
    "        src_ip=row.get(\"Source IP\", \"Unknown\"),\n",
    "        dst_ip=row.get(\"Destination IP\", \"Unknown\"),\n",
    "        protocol=row.get(\"Protocol\", \"Unknown\")\n",
    "    )\n",
    "\n",
    "    # Shorten if too long\n",
    "    if len(playbook_text) > max_playbook_length:\n",
    "        playbook_text = playbook_text[:max_playbook_length] + \"...\"\n",
    "\n",
    "    incident_playbooks[incident] = playbook_text\n",
    "\n",
    "# Map the playbooks to all predictions\n",
    "predictions_df[\"Response_Playbook\"] = predictions_df[\"Predicted_Label\"].map(incident_playbooks)\n",
    "\n",
    "# Save as single CSV\n",
    "output_csv = \"Playbooks.csv\"\n",
    "predictions_df.to_csv(output_csv, index=False)\n",
    "print(f\"\\nâœ… All predictions and playbooks saved in {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
